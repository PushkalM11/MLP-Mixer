{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './../Models')\n",
    "\n",
    "from imagenet1k_dataloader import get_imagenet_loaders\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms as T\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "import timm\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "net = timm.create_model('mixer_b16_224.miil_in21k_ft_in1k', pretrained = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "net.head = Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet1k_data_dir = \"./../Data/imagenet1k/\"\n",
    "test_size = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "train_loader, test_loader = get_imagenet_loaders(imagenet1k_data_dir, \n",
    "                                                 test_size = test_size, \n",
    "                                                 shuffle = True, \n",
    "                                                 batch_size = batch_size, \n",
    "                                                 device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.Tensor()\n",
    "labels = torch.Tensor()\n",
    "\n",
    "tqdm_loader = tqdm(train_loader, desc = \"Inference Train Data\", position = 0, leave = True)\n",
    "for dat in tqdm_loader:\n",
    "    image, label = dat[0], dat[1].cpu().detach()\n",
    "    output = net(image).cpu().detach()\n",
    "    outputs = torch.cat((outputs, output), dim = 0)\n",
    "    labels = torch.cat((labels, label), dim = 0)\n",
    "    tqdm_loader.update(1)\n",
    "tqdm_loader.close()\n",
    "\n",
    "tqdm_loader = tqdm(test_loader, desc = \"Inference Test Data\", position = 0, leave = True)\n",
    "for dat in tqdm_loader:\n",
    "    image, label = dat[0], dat[1].cpu().detach()\n",
    "    output = net(image).cpu().detach()\n",
    "    outputs = torch.cat((outputs, output), dim = 0)\n",
    "    labels = torch.cat((labels, label), dim = 0)\n",
    "    tqdm_loader.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = TSNE(n_components = 2, perplexity = 30, n_iter = 1000, learning_rate = 60)\n",
    "features = m.fit_transform(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = sns.hls_palette(as_cmap = True)\n",
    "f, ax = plt.subplots(figsize = (12, 8))\n",
    "points = ax.scatter(features[:, 0], features[:, 1], c = labels.numpy(), s = 30, cmap = cmap)\n",
    "f.colorbar(points)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLP_mixer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
